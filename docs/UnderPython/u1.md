# A Modern Python Packaging Guide

Packaging is a tedious and dirty job for python developers. The python packaging ecosystem is a mess, and full of historical burdens. You might confused with the different tools and command-line interfaces, and suffer from decision paralysis when it comes to choosing project structures, configuration files, and packaging tools. In the guide, I will give you a brife introduction from create a repo of github to pulish it to pypi and conda in a dictatorial manner.

Up to now, many of python scaffolds have emerged. They provide very convenient ways to create a python project, let developer rid of tiresome configuration. However, under hook, They assist you in using underlying tools such as `setuptools`. Once you want to customize your project, you will find that you have to learn the underlying tools. So, In the guide, an example project will build up from scratch, rely on less dependencies as possible.

To make the guide more readable, I will use a simple project as an example. 

Before we start, we should think what structure of our project choose.

## About project structure

Two popular project layouts are used in python project, each one with its own set of pros and cons[^1][^2]. The first one is called `flat-layout`, also known as *adhoc*. The package folders are placed directly under the project root like this:

```
project_root_directory
├── pyproject.toml  # AND/OR setup.cfg, setup.py
├── ...
├── mypkg/
|   ├── __init__.py
|   ├── ...
|   ├── module.py
|   ├── subpkg1/
|   │   ├── __init__.py
|   │   ├── ...
|   │   └── module1.py
|   └── subpkg2/
|       ├── __init__.py
|       ├── ...
|        └── module2.py
└── tests/
    ├── __init__.py
    ├── ...
    └── test_mypkg.py
```

This layout is very common and practical for using the REPL, but in some situations it can be more error-prone (e.g. during tests or if you have a bunch of folders or Python files hanging around your project root). The structure will bring up a problem: You get **import parity**. The current directory(e.g. root dir) is implicitly included in `sys.path`; but not so when installing & importing from site-packages. Users will never have the same current working directory as you do. For example, once you import the project in the tests in such way: `import mypkg`, it will not import the project in the site-packages but the current directory. So, more people are consider about the second layout, `src-layout` like this:

```
project_root_directory
├── pyproject.toml  # AND/OR setup.cfg, setup.py
├── ...
└── src/  # NOTE: no __init__.py
    └── mypkg/  
        ├── __init__.py
        ├── ...
        ├── module.py
        ├── subpkg1/
        │   ├── __init__.py
        │   ├── ...
        │   └── module1.py
        └── subpkg2/
            ├── __init__.py
            ├── ...
            └── module2.py
```

In this layout, the package `mypkg` is under `src` directory, and the `src` directory is not a package (no `__init__.py`). This constraint has beneficial implications in both testing and packaging: 

1. You will be forced to install the package and test the installed code (e.g.: by installing in a virtualenv). This will ensure that the deployed code works (it's packaged correctly) - otherwise your tests will fail. 

3. It prevents you from readily importing your code in the `setup.py` script. This is a bad practice because it will always blow up if importing the main package or module triggers additional imports for dependencies (which may not be available). 

4. Simpler packaging code and manifest. Without `src` you get messy editable installs (`setup.py develop` or `pip install -e`). Having no separation (no `src` dir) will force setuptools to put your project's root on `sys.path` - with all the junk in it.

8. Less chance for tools to mixup code with non-code.

Also, you will notice that we not include tests in the `src` or packages because tests are concerned with development, not usage. It require addtional dependencies to run. Module discovery tools will trip over your test modules. 

!!! note "module, package and namespace"
    
    Package, module, and namespace are three different concepts in Python:
    
    2. Module: A module is a file containing Python code. It can define functions, classes, and variables, which can be used in other modules or scripts. Modules can be imported into other modules or scripts using the import statement.
    
    1. Package: A package is a collection of modules. It is a way to organize related modules together. A package is represented by a directory containing an `__init__.py` file and can contain other modules or sub-packages.
    
    3. Namespace: A namespace is a mapping between names and objects. It is used to avoid naming conflicts between different modules or packages. Namespaces can be created using the global statement, or by defining functions, classes, or modules. 
    
    In summary, a module is a file containing Python code, a package is a collection of related modules, and a namespace is a mapping between names and objects that helps avoid naming conflicts. We will invoke the namespace in the following sections.

## About setuptools

After understanding the structure, we can create our example project. We will first package the pure python code, install and test it, which ensure that our configuration is correct. Next, we will introduce extra building system to hybrid C++ or others. Our project will be named `mypkg`, and the structure is like this:

```
├── pyproject.toml  # and/or setup.cfg
├── setup.py
├── README.md  # ...and other optional declearation
├── src
│   └── mypkg
│       ├── __init__.py
│       ├── ...
│       ├── module.py
|
└── tests
    ├── __init__.py
    ├── ...
    └── test_mypkg.py
```

Two new files are include in our project: `pyproject.toml` and `setup.py`. `pyproject.toml` is a static configuration file, and the distribution can then be generated with any packaging tools.

!!! note "distribution and wheel"

    Source distribution(aka. sdist) provides metadata and the essential source files needed for installing by a tool like `pip`, or for generating a Built distribution. It only need to be moved to the correct location on the target system.

    Built distribution(aka. wheel) requires a build step before it can be installed. This format does not imply that Python files have to be precompiled (Wheel intentionally does not include compiled Python files).

First we should declear the metadata of our project in `pyproject.toml`:

```toml
[project]
name = "proj"
authors = [
    {name = "Roy Kid", email = "lijichen365@gmail.com"},
]
description = "My package description"
readme = "README.rst"
requires-python = ">=3.7"
keywords = ["one", "two"]
license = {text = "BSD-3-Clause"}
classifiers = [
    "Framework :: Django",
    "Programming Language :: Python :: 3",
]
dependencies = [
    "requests",
    'importlib-metadata; python_version<"3.8"',
]
dynamic = ["version"]  # optional

[tool.setuptools.dynamic]  # optional
version = {attr = "my_package.VERSION"}
readme = {file = ["README.rst", "USAGE.rst"]}
```

Next, we need to designate `build-system` requirements and the build backend:
```toml
[build-system]
requires = ["setuptools", "setuptools-scm"]
build-backend = "setuptools.build_meta"
```
Note that `setuptools-scm` is a plugin for setuptools that enables setuptools to get metadata and a list of files from SCM (Source Code Management, e.g. `git` or `hg`). In this way we can not need write `MINIFEST.in` to determine which files to include in the source distribution. If we do not use `setuptools-scm`, we also can specify the files to include in the source distribution in `pyproject.toml`:

```toml
[tool.setuptools.packages]
find = {}  # Scan the project directory with the default parameters

# OR
[tool.setuptools.packages.find]
# All the following settings are optional:
where = ["src"]  # ["."] by default
include = ["mypackage*"]  # ["*"] by default
exclude = ["mypackage.tests*"]  # empty by default
namespaces = false  # true by default
```
!!! warning "non-py file may not include"

    As mentioned above, the source distribution only need to include the essential source files needed for installing. So if we want to include non-py files, we need to specify them in `MANIFEST.in`


The doc[^3] recommend users to expose as much as possible configuration in a more declarative way via the `pyproject.toml` or `setup.cfg`, and keep the `setup.py` minimal with only the dynamic parts (or even omit it completely if applicable).

!!! note "different dependency styles"

    Three types of dependency styles offered by setuptools: 1. build system requirement, 2. required dependency and 3. optional dependency. Build system requirement is what project replies on when building and packaging, such as `setuptools` and `pybind11`. Required dependency is what project replies on when running, such as `numpy`. Optional dependency is what project replies on when running, but not required, such as `matplotlib`. 

In `setup.py`, we only need to write the dynamic parts. Before we introduce cpp extension, pure python project only need this if you configure the `pyproject.toml` correctly:

```python
from setuptools import setup

setup()
```

Don't think it is too simple, it will be more complex when we introduce cpp extension. We will start to write, test and package our code in the next section.

## Write and Test

```
├── pyproject.toml  # and/or setup.cfg
├── setup.py
├── README.md  # ...and other optional declearation
├── src
│   └── mypkg
│       ├── __init__.py
│       ├── ...
│       ├── sum.py
|
└── tests
    ├── __init__.py
    ├── ...
    └── test_sum.py
```
We can write a simple function `sum` in `src/mypkg/sum.py`:

```python
def sum(a, b):
    return a + b
```

and a corresponding test case in `tests/test_sum.py`:

```python
from mypkg.sum import sum
def test_sum():
    assert sum(1, 2) == 3
```

We shoud import `mypkg` in a way that our user do. That means we CAN NOT import `mypkg` by a relative path from our current work directory(and don't use `sys.path.append` please), and that is `src-layout` prevent you do.
Instead, we should install our package in editable mode:

```bash
pip install -e .
# OR 
python -m pip install . --editable
```

In this way, we can mimic the package is installed in user's system and import it in a way that our user do. Also, when we 

## References

[1] https://blog.ionelmc.ro/2014/05/25/python-packaging/#the-structure
